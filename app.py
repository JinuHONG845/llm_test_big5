import streamlit as st
import pandas as pd
import numpy as np
import json
import openai
import anthropic
import google.generativeai as genai
import time
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import random  # íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€

# ì•± ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="Big 5 ì„±ê²© ê²€ì‚¬",
    page_icon="ğŸ§ª",
    layout="wide"
)

# ì „ì—­ ë³€ìˆ˜ë¡œ test_mode ì„¤ì •
test_mode = "ì „ì²´ í…ŒìŠ¤íŠ¸ (ë¶„í•  ì‹¤í–‰)"  # ê¸°ë³¸ê°’ ì„¤ì •

# ì—¬ë°± ì¤„ì •ì„ ìœ„í•œ CSS
st.markdown("""
    <style>
        .block-container {
            padding-top: 1rem;
            padding-bottom: 1rem;
            padding-left: 3rem;
            padding-right: 3rem;
            max-width: 100rem;
        }
        .element-container {
            margin-bottom: 1.5rem;
        }
        .stDataFrame {
            width: 100%;
        }
        .dataframe {
            margin-top: 1rem;
            margin-bottom: 2rem;
            font-size: 14px;
        }
        table {
            border-collapse: collapse;
            border-spacing: 0;
            width: 100%;
        }
        th {
            background-color: #f0f2f6;
            font-weight: bold;
            padding: 12px 8px !important;
        }
        td {
            padding: 10px 8px !important;
        }
        h3 {
            margin-top: 2rem !important;
            margin-bottom: 1rem !important;
            padding: 0.5rem 0;
            border-bottom: 2px solid #f0f2f6;
            color: #0e1117;
        }
        .stProgress > div > div {
            background-color: #00cc99;
        }
    </style>
""", unsafe_allow_html=True)

# ê¸°ë³¸ íƒ€ì´í‹€ ì„¤ì •
st.title("LLM Big 5 Test")

# JSON íŒŒì¼ë“¤ ë¡œë“œ
try:
    with open('persona.json', 'r') as f:
        personas = json.load(f)
    with open('IPIP.json', 'r') as f:
        ipip_questions = json.load(f)
    with open('BFI.json', 'r') as f:
        bfi_questions = json.load(f)
except FileNotFoundError as e:
    st.error(f"í•„ìš”í•œ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    st.stop()
except json.JSONDecodeError as e:
    st.error(f"JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
    st.stop()

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    # ì‹¤í—˜ ëª¨ë“œ ì„ íƒ
    test_mode = st.radio(
        "ì‹¤í—˜ ëª¨ë“œ ì„ íƒ",
        ("í˜ë¥´ì†Œë‚˜ í…ŒìŠ¤íŠ¸", "ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸"),
        horizontal=True
    )
    
    st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€

    if test_mode == "í˜ë¥´ì†Œë‚˜ í…ŒìŠ¤íŠ¸":
        # === LLM ì„¤ì • ì„¹ì…˜ ===
        st.title("LLM ì„¤ì •")
        llm_choice = st.radio(
            "LLM ì„ íƒ",
            ("GPT", "Claude", "Gemini"),
            horizontal=True,
            key="main_llm"
        )

        # LLM ì„ íƒì— ë”°ë¥¸ ì„¸ë¶€ ëª¨ë¸ ì„ íƒ
        if llm_choice == "GPT":
            model_choice = st.radio(
                "GPT ëª¨ë¸ ì„ íƒ",
                ("GPT-4 Turbo", "GPT-3.5 Turbo"),
                horizontal=True,
                help="GPT-4 TurboëŠ” ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦½ë‹ˆë‹¤. GPT-3.5 TurboëŠ” ë” ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                key="main_model_gpt"
            )
        elif llm_choice == "Claude":
            model_choice = st.radio(
                "Claude ëª¨ë¸ ì„ íƒ",
                ("Claude 3 Sonnet", "Claude 3 Haiku"),
                horizontal=True,
                help="Sonnetì€ ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦½ë‹ˆë‹¤. HaikuëŠ” ë” ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                key="main_model_claude"
            )
        else:  # Gemini
            model_choice = st.radio(
                "Gemini ëª¨ë¸ ì„ íƒ",
                ("Gemini Pro",),  # ë‹¨ì¼ ì˜µì…˜
                horizontal=True,
                help="í˜„ì¬ Gemini Pro ëª¨ë¸ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                key="main_model_gemini"
            )
        
        # ëŒ€ì¡°êµ° ë³€ìˆ˜ ì´ˆê¸°í™”
        control_llm_choice = None
        control_model_choice = None

    else:  # ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸
        # === ëŒ€ì¡°êµ° LLM ì„¤ì • ===
        st.title("ëŒ€ì¡°êµ° LLM ì„¤ì •")
        
        # ëŒ€ì¡°êµ° LLM ì„ íƒ
        control_llm_choice = st.radio(
            "LLM ì„ íƒ",
            ("GPT", "Claude", "Gemini"),
            horizontal=True,
            key="control_llm"
        )

        # ëŒ€ì¡°êµ° ì„¸ë¶€ ëª¨ë¸ ì„ íƒ
        if control_llm_choice == "GPT":
            control_model_choice = st.radio(
                "GPT ëª¨ë¸ ì„ íƒ",
                ("GPT-4 Turbo", "GPT-3.5 Turbo"),
                horizontal=True,
                help="GPT-4 TurboëŠ” ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦½ë‹ˆë‹¤. GPT-3.5 TurboëŠ” ë” ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                key="control_model_gpt"
            )
        elif control_llm_choice == "Claude":
            control_model_choice = st.radio(
                "Claude ëª¨ë¸ ì„ íƒ",
                ("Claude 3 Sonnet", "Claude 3 Haiku"),
                horizontal=True,
                help="Sonnetì€ ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦½ë‹ˆë‹¤. HaikuëŠ” ë” ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                key="control_model_claude"
            )
        else:  # Gemini
            control_model_choice = st.radio(
                "Gemini ëª¨ë¸ ì„ íƒ",
                ("Gemini Pro",),  # ë‹¨ì¼ ì˜µì…˜
                horizontal=True,
                help="í˜„ì¬ Gemini Pro ëª¨ë¸ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                key="control_model_gemini"
            )
        
        # LLM ë³€ìˆ˜ ì´ˆê¸°í™”
        llm_choice = None
        model_choice = None

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€)
if 'control_results' not in st.session_state:
    st.session_state.control_results = {
        'ipip': pd.DataFrame(),
        'bfi': pd.DataFrame(),
        'completed_batches': set()
    }

# API í‚¤ ì„¤ì •
if llm_choice == "GPT":
    api_key = st.secrets.get("OPENAI_API_KEY")
    if not api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    openai.api_key = api_key
elif llm_choice == "Claude":
    api_key = st.secrets.get("ANTHROPIC_API_KEY")
    if not api_key:
        st.error("Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    client = anthropic.Anthropic(api_key=api_key)
else:  # Gemini
    api_key = st.secrets.get("GOOGLE_API_KEY")
    if not api_key:
        st.error("Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    genai.configure(api_key=api_key)

@retry(
    stop=stop_after_attempt(5),  # ìµœëŒ€ 5ë²ˆ ì¬ì‹œë„
    wait=wait_exponential(multiplier=1, min=4, max=20),  # 4~20ì´ˆ ì‚¬ì´ ëŒ€ê¸°ì‹œê°„
    retry=(
        retry_if_exception_type(openai.APIError) |
        retry_if_exception_type(openai.APIConnectionError) |
        retry_if_exception_type(openai.RateLimitError) |
        retry_if_exception_type(anthropic.APIError) |
        retry_if_exception_type(anthropic.APIConnectionError) |
        retry_if_exception_type(anthropic.RateLimitError)
    )
)
def get_llm_response(persona, questions, test_type):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ í˜ë¥´ì†Œë‚˜ì˜ í…ŒìŠ¤íŠ¸ ì‘ë‹µì„ ìƒì„±"""
    try:
        # ì§ˆë¬¸ ëª©ë¡ ì¤€ë¹„
        if test_type == 'IPIP':
            question_list = [q['item'] for q in questions]
            scale_description = """1 = Very inaccurate
2 = Moderately inaccurate
3 = Neither
4 = Moderately accurate
5 = Very accurate"""
        else:  # BFI
            question_list = [q['question'] for q in questions]
            scale_description = """1 = Disagree Strongly
2 = Disagree a little
3 = Neither agree nor disagree
4 = Agree a little
5 = Agree strongly"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""Based on this persona: {', '.join(persona['personality'])}

For each question, provide a rating from 1-5 where:
{scale_description}

Return ONLY a JSON object in this exact format:
{{
    "responses": [
        {{"question": "<question text>", "score": <1-5>}},
        ...
    ]
}}

Questions to rate:
{json.dumps(question_list, indent=2)}"""
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                if llm_choice == "GPT":
                    model_name = "gpt-4-turbo-preview" if model_choice == "GPT-4 Turbo" else "gpt-3.5-turbo"
                    response = openai.chat.completions.create(
                        model=model_name,
                        messages=[
                            {"role": "system", "content": "You are a helpful assistant that responds only in valid JSON format."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=1.0,
                        timeout=30
                    )
                    content = response.choices[0].message.content
                    
                elif llm_choice == "Claude":
                    model_name = "claude-3-sonnet-20240229" if model_choice == "Claude 3 Sonnet" else "claude-3-haiku-20240307"
                    response = client.messages.create(
                        model=model_name,
                        max_tokens=2000,
                        system="You are a helpful assistant that responds only in valid JSON format.",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=1.0,
                        timeout=30
                    )
                    content = response.content[0].text
                    
                else:  # Gemini
                    model_name = 'gemini-pro' if model_choice == "Gemini Pro" else 'gemini-nano'
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(
                        prompt,
                        generation_config=genai.types.GenerationConfig(
                            temperature=1.0
                        )
                    )
                    content = response.text
                
                # JSON íŒŒì‹± ë° ê²€ì¦
                if content.startswith('```') and content.endswith('```'):
                    content = content.split('```')[1]
                    if content.startswith('json'):
                        content = content[4:]
                
                result = json.loads(content.strip())
                
                # ì‘ë‹µ ê²€ì¦
                if not result or 'responses' not in result:
                    raise ValueError("Invalid response format")
                if len(result['responses']) != len(question_list):
                    raise ValueError("Incomplete response")
                
                time.sleep(2)  # API í˜¸ì¶œ ì‚¬ì´ì— 2ì´ˆ ëŒ€ê¸°
                return result
                
            except (json.JSONDecodeError, ValueError) as e:
                if attempt == max_retries - 1:
                    st.error(f"ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    raise e
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                continue
                
            except Exception as e:
                st.error(f"LLM API ì˜¤ë¥˜: {str(e)}")
                if attempt == max_retries - 1:
                    raise e
                time.sleep(2 ** attempt)
                continue
                
    except Exception as e:
        st.error(f"ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise e

# ë°°ì¹˜ í¬ê¸° ì¡°ì • (ëª¨ë¸ì— ë”°ë¼)
def get_batch_size(model):
    if model in ["GPT-4 Turbo", "Claude 3 Sonnet", "Gemini Pro"]:
        return 25, 5  # IPIP ë°°ì¹˜ í¬ê¸°, BFI ë°°ì¹˜ í¬ê¸°
    else:
        return 10, 3  # ë” ì‘ì€ ë°°ì¹˜ í¬ê¸°

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'accumulated_results' not in st.session_state:
    st.session_state.accumulated_results = {
        'ipip': pd.DataFrame(),
        'bfi': pd.DataFrame(),
        'completed_batches': set()
    }

if test_mode == "ì „ì²´ í…ŒìŠ¤íŠ¸ (ë¶„í•  ì‹¤í–‰)":
    # IPIP í…ŒìŠ¤íŠ¸ ì„¹ì…˜
    st.write("### IPIP í˜ë¥´ì†Œë‚˜ ë°°ì¹˜ ì„ íƒ")
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        ipip_batch1 = st.button("IPIP 1-10ë²ˆ", 
                          disabled='ipip_batch1' in st.session_state.accumulated_results['completed_batches'])
    with col2:
        ipip_batch2 = st.button("IPIP 11-20ë²ˆ", 
                          disabled='ipip_batch2' in st.session_state.accumulated_results['completed_batches'])
    with col3:
        ipip_batch3 = st.button("IPIP 21-30ë²ˆ", 
                          disabled='ipip_batch3' in st.session_state.accumulated_results['completed_batches'])
    with col4:
        ipip_batch4 = st.button("IPIP 31-40ë²ˆ", 
                          disabled='ipip_batch4' in st.session_state.accumulated_results['completed_batches'])
    with col5:
        ipip_batch5 = st.button("IPIP 41-50ë²ˆ", 
                          disabled='ipip_batch5' in st.session_state.accumulated_results['completed_batches'])

    # BFI í…ŒìŠ¤íŠ¸ ì„¹ì…˜
    st.write("### BFI í˜ë¥´ì†Œë‚˜ ë°°ì¹˜ ì„ íƒ")
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        bfi_batch1 = st.button("BFI 1-10ë²ˆ", 
                          disabled='bfi_batch1' in st.session_state.accumulated_results['completed_batches'])
    with col2:
        bfi_batch2 = st.button("BFI 11-20ë²ˆ", 
                          disabled='bfi_batch2' in st.session_state.accumulated_results['completed_batches'])
    with col3:
        bfi_batch3 = st.button("BFI 21-30ë²ˆ", 
                          disabled='bfi_batch3' in st.session_state.accumulated_results['completed_batches'])
    with col4:
        bfi_batch4 = st.button("BFI 31-40ë²ˆ", 
                          disabled='bfi_batch4' in st.session_state.accumulated_results['completed_batches'])
    with col5:
        bfi_batch5 = st.button("BFI 41-50ë²ˆ", 
                          disabled='bfi_batch5' in st.session_state.accumulated_results['completed_batches'])

    # ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™”"):
        st.session_state.accumulated_results = {
            'ipip': pd.DataFrame(),
            'bfi': pd.DataFrame(),
            'completed_batches': set()
        }
        st.rerun()

def run_batch_test(batch_name, start_idx, end_idx, test_type='IPIP', is_control=False):
    # ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸ì¼ ê²½ìš° ë¹ˆ í˜ë¥´ì†Œë‚˜ ì‚¬ìš©
    if is_control:
        personas_to_test = [{"personality": []}]  # ë¹ˆ í˜ë¥´ì†Œë‚˜
    else:
        personas_to_test = personas[start_idx:end_idx]  # ê¸°ì¡´ í˜ë¥´ì†Œë‚˜
    
    ipip_batch_size, bfi_batch_size = get_batch_size(model_choice)
    
    # DataFrame ì´ˆê¸°í™” ë˜ëŠ” ê¸°ì¡´ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
    if st.session_state.accumulated_results['ipip'].empty:
        ipip_df = pd.DataFrame(
            np.nan, 
            index=[f"Persona {i+1}" for i in range(len(personas))] + ['Average'],
            columns=[f"Q{i+1}" for i in range(300)]
        )
    else:
        ipip_df = st.session_state.accumulated_results['ipip'].copy()
    
    if st.session_state.accumulated_results['bfi'].empty:
        bfi_df = pd.DataFrame(
            np.nan, 
            index=[f"Persona {i+1}" for i in range(len(personas))] + ['Average'],
            columns=[f"Q{i+1}" for i in range(44)]
        )
    else:
        bfi_df = st.session_state.accumulated_results['bfi'].copy()

    # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
    if test_type == 'IPIP':
        st.write("### IPIP í…ŒìŠ¤íŠ¸ ì§„í–‰ ìƒí™©")
        progress_bar = st.progress(0)
        result_table = st.empty()
        
        # IPIP í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for i, persona in enumerate(personas_to_test, start=start_idx):
            # IPIP í…ŒìŠ¤íŠ¸
            all_ipip_scores = []
            for j in range(0, 300, ipip_batch_size):
                try:
                    batch_end = min(j + ipip_batch_size, 300)
                    batch_questions = ipip_questions['items'][j:batch_end]
                    
                    ipip_responses = get_llm_response(persona, batch_questions, 'IPIP')
                    if ipip_responses and 'responses' in ipip_responses:
                        scores = [r['score'] for r in ipip_responses['responses']]
                        all_ipip_scores.extend(scores)
                        
                        current_scores = ipip_df.iloc[i].copy()
                        current_scores[j:j+len(scores)] = scores
                        ipip_df.iloc[i] = current_scores
                        ipip_df.loc['Average'] = ipip_df.iloc[:-1].mean()
                        
                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (1.0ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì •)
                        progress = min(1.0, ((i - start_idx) * 300 + j + len(scores)) / (len(personas_to_test) * 300))
                        progress_bar.progress(progress)
                        
                        # DataFrame ì—…ë°ì´íŠ¸
                        result_table.dataframe(
                            ipip_df.fillna(0).round().astype(int).style
                                .background_gradient(cmap='YlOrRd', vmin=1, vmax=5)
                                .format("{:d}")
                                .set_properties(**{
                                    'width': '40px',
                                    'text-align': 'center',
                                    'font-size': '13px',
                                    'border': '1px solid #e6e6e6'
                                })
                                .set_table_styles([
                                    {'selector': 'th', 'props': [
                                        ('background-color', '#f0f2f6'),
                                        ('color', '#0e1117'),
                                        ('font-weight', 'bold'),
                                        ('text-align', 'center')
                                    ]},
                                    {'selector': 'td', 'props': [
                                        ('text-align', 'center')
                                    ]},
                                    {'selector': 'table', 'props': [
                                        ('width', '100%'),
                                        ('margin', '0 auto')
                                    ]}
                                ]),
                            use_container_width=True
                        )
                        
                        time.sleep(1)  # ì‹œê°ì  íš¨ê³¼ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                        
                except Exception as e:
                    st.error(f"IPIP í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ (í˜ë¥´ì†Œë‚˜ {i+1}, ë¬¸í•­ {j}-{batch_end}): {str(e)}")
                    continue
                
    else:  # BFI
        st.write("### BFI í…ŒìŠ¤íŠ¸ ì§„í–‰ ìƒí™©")
        progress_bar = st.progress(0)
        result_table = st.empty()
        
        # BFI í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for i, persona in enumerate(personas_to_test, start=start_idx):
            # BFI í…ŒìŠ¤íŠ¸ (ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„)
            for j in range(0, 44, bfi_batch_size):
                try:
                    batch_end = min(j + bfi_batch_size, 44)
                    batch_questions = bfi_questions[j:batch_end]
                    
                    bfi_responses = get_llm_response(persona, batch_questions, 'BFI')
                    if bfi_responses and 'responses' in bfi_responses:
                        scores = [r['score'] for r in bfi_responses['responses']]
                        
                        current_scores = bfi_df.iloc[i].copy()
                        current_scores[j:j+len(scores)] = scores
                        bfi_df.iloc[i] = current_scores
                        bfi_df.loc['Average'] = bfi_df.iloc[:-1].mean()
                        
                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (1.0ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì •)
                        progress = min(1.0, ((i - start_idx) * 44 + j + len(scores)) / (len(personas_to_test) * 44))
                        progress_bar.progress(progress)
                        
                        # DataFrame ì—…ë°ì´íŠ¸
                        result_table.dataframe(
                            bfi_df.fillna(0).round().astype(int).style
                                .background_gradient(cmap='YlOrRd', vmin=1, vmax=5)
                                .format("{:d}")
                                .set_properties(**{
                                    'width': '40px',
                                    'text-align': 'center',
                                    'font-size': '13px',
                                    'border': '1px solid #e6e6e6'
                                })
                                .set_table_styles([
                                    {'selector': 'th', 'props': [
                                        ('background-color', '#f0f2f6'),
                                        ('color', '#0e1117'),
                                        ('font-weight', 'bold'),
                                        ('text-align', 'center')
                                    ]},
                                    {'selector': 'td', 'props': [
                                        ('text-align', 'center')
                                    ]},
                                    {'selector': 'table', 'props': [
                                        ('width', '100%'),
                                        ('margin', '0 auto')
                                    ]}
                                ]),
                            use_container_width=True
                        )
                        
                        time.sleep(1)  # ì‹œê°ì  íš¨ê³¼ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                        
                except Exception as e:
                    st.error(f"BFI í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ (í˜ë¥´ì†Œë‚˜ {i+1}, ë¬¸í•­ {j}-{batch_end}): {str(e)}")
                    continue

    # ê²°ê³¼ ëˆ„ì  ì €ì¥
    st.session_state.accumulated_results['ipip'] = ipip_df
    st.session_state.accumulated_results['bfi'] = bfi_df
    st.session_state.accumulated_results['completed_batches'].add(batch_name)

    return ipip_df, bfi_df

# ë°°ì¹˜ ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬
if test_mode == "ì „ì²´ í…ŒìŠ¤íŠ¸ (ë¶„í•  ì‹¤í–‰)":
    if ipip_batch1:
        ipip_df, _ = run_batch_test('ipip_batch1', 0, 10, test_type='IPIP')
    elif ipip_batch2:
        ipip_df, _ = run_batch_test('ipip_batch2', 10, 20, test_type='IPIP')
    elif ipip_batch3:
        ipip_df, _ = run_batch_test('ipip_batch3', 20, 30, test_type='IPIP')
    elif ipip_batch4:
        ipip_df, _ = run_batch_test('ipip_batch4', 30, 40, test_type='IPIP')
    elif ipip_batch5:
        ipip_df, _ = run_batch_test('ipip_batch5', 40, 50, test_type='IPIP')
    elif bfi_batch1:
        _, bfi_df = run_batch_test('bfi_batch1', 0, 10, test_type='BFI')
    elif bfi_batch2:
        _, bfi_df = run_batch_test('bfi_batch2', 10, 20, test_type='BFI')
    elif bfi_batch3:
        _, bfi_df = run_batch_test('bfi_batch3', 20, 30, test_type='BFI')
    elif bfi_batch4:
        _, bfi_df = run_batch_test('bfi_batch4', 30, 40, test_type='BFI')
    elif bfi_batch5:
        _, bfi_df = run_batch_test('bfi_batch5', 40, 50, test_type='BFI')
elif test_mode == "ê°„ì´ í…ŒìŠ¤íŠ¸ (ëœë¤ 3ê°œ í˜ë¥´ì†Œë‚˜)":
    # ëœë¤ í˜ë¥´ì†Œë‚˜ ì„ íƒ
    random_personas = random.sample(personas, 3)
    # ê°„ì´ í…ŒìŠ¤íŠ¸ ë¡œì§ ì‹¤í–‰
    # ... (ê¸°ì¡´ ê°„ì´ í…ŒìŠ¤íŠ¸ ì½”ë“œ) ...

# CSV íŒŒì¼ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ë¶€ë¶„
if not st.session_state.accumulated_results['ipip'].empty:
    csv_data = pd.concat([
        st.session_state.accumulated_results['ipip'].add_prefix('IPIP_Q'),
        st.session_state.accumulated_results['bfi'].add_prefix('BFI_Q')
    ], axis=1)
    
    st.download_button(
        label="ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
        data=csv_data.to_csv(index=True, float_format='%.10f'),
        file_name="personality_test_results.csv",
        mime="text/csv"
    )

# ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜ ìˆ˜ì •
def run_control_batch_test(batch_name, start_idx, end_idx, test_type='IPIP'):
    empty_persona = {"personality": []}  # ë¹ˆ í˜ë¥´ì†Œë‚˜
    
    # DataFrame ì´ˆê¸°í™” ë˜ëŠ” ê¸°ì¡´ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
    if st.session_state.control_results[test_type.lower()].empty:
        df = pd.DataFrame(
            np.nan,
            index=[f"Control {i+1}" for i in range(num_control_tests)] + ['Average'],
            columns=[f"Q{i+1}" for i in range(300 if test_type == 'IPIP' else 44)]
        )
    else:
        df = st.session_state.control_results[test_type.lower()].copy()

    # ì§„í–‰ ìƒí™© í‘œì‹œ
    st.write(f"### {test_type} ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸ ì§„í–‰ ìƒí™©")
    progress_bar = st.progress(0)
    result_table = st.empty()

    # ê° ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    for test_num in range(num_control_tests):
        try:
            responses = get_llm_response(empty_persona, 
                                       ipip_questions['items'][start_idx:end_idx] if test_type == 'IPIP' else bfi_questions[start_idx:end_idx], 
                                       test_type)
            
            if responses and 'responses' in responses:
                scores = [r['score'] for r in responses['responses']]
                df.iloc[test_num, start_idx:end_idx] = scores
                df.loc['Average'] = df.iloc[:-1].mean()

                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                progress = (test_num + 1) / num_control_tests
                progress_bar.progress(progress)

                # ê²°ê³¼ í…Œì´ë¸” ì—…ë°ì´íŠ¸
                result_table.dataframe(
                    df.fillna(0).round().astype(int).style
                        .background_gradient(cmap='YlOrRd', vmin=1, vmax=5)
                        .format("{:d}")
                        .set_properties(**{
                            'width': '40px',
                            'text-align': 'center',
                            'font-size': '13px',
                            'border': '1px solid #e6e6e6'
                        })
                )

        except Exception as e:
            st.error(f"ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸ {test_num+1} ì‹¤íŒ¨: {str(e)}")
            continue

    # ê²°ê³¼ ì €ì¥
    st.session_state.control_results[test_type.lower()] = df
    st.session_state.control_results['completed_batches'].add(batch_name)

    return df

# ë©”ì¸ UIì—ì„œ ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸ ë²„íŠ¼ ì²˜ë¦¬
if test_mode == "ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸":
    st.write("### IPIP ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸")
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        if st.button("IPIP 1-10", key="control_ipip_1"):
            run_batch_test('ipip_1', 0, 10, 'IPIP', is_control=True)
    with col2:
        if st.button("IPIP 11-20", key="control_ipip_2"):
            run_batch_test('ipip_2', 10, 20, 'IPIP', is_control=True)
    with col3:
        if st.button("IPIP 21-30", key="control_ipip_3"):
            run_batch_test('ipip_3', 20, 30, 'IPIP', is_control=True)
    with col4:
        if st.button("IPIP 31-40", key="control_ipip_4"):
            run_batch_test('ipip_4', 30, 40, 'IPIP', is_control=True)
    with col5:
        if st.button("IPIP 41-50", key="control_ipip_5"):
            run_batch_test('ipip_5', 40, 50, 'IPIP', is_control=True)

    st.write("### BFI ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸")
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        if st.button("BFI 1-10", key="control_bfi_1"):
            run_batch_test('bfi_1', 0, 10, 'BFI', is_control=True)
    with col2:
        if st.button("BFI 11-20", key="control_bfi_2"):
            run_batch_test('bfi_2', 10, 20, 'BFI', is_control=True)
    with col3:
        if st.button("BFI 21-30", key="control_bfi_3"):
            run_batch_test('bfi_3', 20, 30, 'BFI', is_control=True)
    with col4:
        if st.button("BFI 31-40", key="control_bfi_4"):
            run_batch_test('bfi_4', 30, 40, 'BFI', is_control=True)
    with col5:
        if st.button("BFI 41-50", key="control_bfi_5"):
            run_batch_test('bfi_5', 40, 50, 'BFI', is_control=True)

    # ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ëŒ€ì¡°êµ° í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™”", key="control_reset"):
        st.session_state.control_results = {
            'ipip': pd.DataFrame(),
            'bfi': pd.DataFrame(),
            'completed_batches': set()
        }
        st.rerun()

elif test_mode == "í˜ë¥´ì†Œë‚˜ í…ŒìŠ¤íŠ¸":
    st.write("### IPIP í˜ë¥´ì†Œë‚˜ í…ŒìŠ¤íŠ¸")
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        if st.button("IPIP 1-10", key="persona_ipip_1"):
            run_batch_test('ipip_1', 0, 10, 'IPIP', is_control=False)
    with col2:
        if st.button("IPIP 11-20", key="persona_ipip_2"):
            run_batch_test('ipip_2', 10, 20, 'IPIP', is_control=False)
    with col3:
        if st.button("IPIP 21-30", key="persona_ipip_3"):
            run_batch_test('ipip_3', 20, 30, 'IPIP', is_control=False)
    with col4:
        if st.button("IPIP 31-40", key="persona_ipip_4"):
            run_batch_test('ipip_4', 30, 40, 'IPIP', is_control=False)
    with col5:
        if st.button("IPIP 41-50", key="persona_ipip_5"):
            run_batch_test('ipip_5', 40, 50, 'IPIP', is_control=False)

    st.write("### BFI í˜ë¥´ì†Œë‚˜ í…ŒìŠ¤íŠ¸")
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        if st.button("BFI 1-10", key="persona_bfi_1"):
            run_batch_test('bfi_1', 0, 10, 'BFI', is_control=False)
    with col2:
        if st.button("BFI 11-20", key="persona_bfi_2"):
            run_batch_test('bfi_2', 10, 20, 'BFI', is_control=False)
    with col3:
        if st.button("BFI 21-30", key="persona_bfi_3"):
            run_batch_test('bfi_3', 20, 30, 'BFI', is_control=False)
    with col4:
        if st.button("BFI 31-40", key="persona_bfi_4"):
            run_batch_test('bfi_4', 30, 40, 'BFI', is_control=False)
    with col5:
        if st.button("BFI 41-50", key="persona_bfi_5"):
            run_batch_test('bfi_5', 40, 50, 'BFI', is_control=False)